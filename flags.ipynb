{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981cff4a-2f70-4aba-90b5-29c75f6732d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# x\n",
    "from test_cook import *\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b8680ea-d88b-4873-8082-8643091c0bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %reload_ext autotime\n",
    "except:\n",
    "    %pip install ipython-autotime ipywidgets openpyxl\n",
    "    import IPython\n",
    "    IPython.display.clear_output()\n",
    "%reload_ext autotime\n",
    "\n",
    "import pathlib, shutil, warnings, numpy as np, pandas as pd\n",
    "seed = 42\n",
    "root = pathlib.Path('/Volumes/aiml')\n",
    "source = root / 'scook/scook_files/admitted_flags_raw'\n",
    "target = root / 'flags/flags_volume'\n",
    "# shutil.rmtree(target, ignore_errors=True) # if you want a fresh restart\n",
    "\n",
    "############ helper functions I use in many project ############\n",
    "pd.options.display.max_columns = None\n",
    "[warnings.filterwarnings(action='ignore', message=f\".*{w}.*\") for w in [\n",
    "    \"Could not infer format, so each element will be parsed individually, falling back to `dateutil`\",\n",
    "    \"Engine has switched to 'python' because numexpr does not support extension array dtypes\",\n",
    "    \"The default of observed=False is deprecated and will be changed to True in a future version of pandas\",\n",
    "    \"errors='ignore' is deprecated and will raise in a future version\",\n",
    "    \"The behavior of DataFrame concatenation with empty or all-NA entries is deprecated\",\n",
    "    \"The behavior of array concatenation with empty entries is deprecated\",\n",
    "    \"DataFrame is highly fragmented\",\n",
    "]]\n",
    "\n",
    "def disp(df, rows=4, head=True):\n",
    "    with pd.option_context('display.min_rows', rows, 'display.max_rows', rows):\n",
    "        display(df.head(rows) if head else df.tails(rows))\n",
    "\n",
    "def to_numeric(df, downcast='integer', errors='ignore', **kwargs):\n",
    "    \"\"\"convert to numeric dtypes if possible\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .apply(lambda s: s.astype('string').str.lower().str.strip() if s.dtype in ['object','string'] else s)  # prep strings\n",
    "        .apply(lambda s: s if pd.api.types.is_datetime64_any_dtype(s) else pd.to_numeric(s, downcast=downcast, errors=errors, **kwargs))  # convert to numeric if possible\n",
    "        .convert_dtypes()  # convert to new nullable dtypes\n",
    "    )\n",
    "\n",
    "def prep(df, **kwargs):\n",
    "    h = lambda x: x.to_numeric(**kwargs).rename(columns=lambda s: s.lower().strip().replace(' ','_').replace('-','_') if isinstance(s, str) else s)\n",
    "    idx = h(df[[]].reset_index())  # drop columns, reset_index to move index to columns, then apply g\n",
    "    return h(df).reset_index(drop=True).set_index(pd.MultiIndex.from_frame(idx))  # set idx back to df's index\n",
    "\n",
    "def wrap(fcn):\n",
    "    \"\"\"Make new methods work for Series and DataFrames\"\"\"\n",
    "    def wrapper(S, *args, **kwargs):\n",
    "        df = fcn(pd.DataFrame(S), *args, **kwargs)\n",
    "        return None if df is None else df.squeeze() if isinstance(S, pd.Series) else df  # squeeze to series if input was series\n",
    "    return wrapper\n",
    "\n",
    "for f in [disp, to_numeric, prep]:\n",
    "    \"\"\"monkey-patch my helpers into Pandas Series & DataFrame classees so we can use df.method syntax\"\"\"\n",
    "    setattr(pd.DataFrame, f.__name__, f)\n",
    "    setattr(pd.Series, f.__name__, wrap(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e19d7681-5610-42cc-8fad-bc2588d9ac04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get id-pidm crosswalk so we can replace id by pidm in flags below\n",
    "query = f\"\"\"\n",
    "select distinct\n",
    "    spriden_id as id,\n",
    "    spriden_pidm as pidm\n",
    "from\n",
    "    dev.bronze.saturnspriden\n",
    "where\n",
    "    spriden_change_ind is null\n",
    "    and spriden_activity_date between '2000-09-01' and '2025-09-01'\n",
    "    and spriden_id REGEXP '^[0-9]+'\n",
    "\"\"\"\n",
    "spriden = spark.sql(query).toPandas()#.prep()\n",
    "spriden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729baab9-0c39-4902-a6f3-b717ca02ed03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for src in sorted(source.iterdir(), reverse=True):\n",
    "    a,b = src.name.lower().split('.')\n",
    "    if b != 'xlsx' or 'melt' in a or 'admitted' not in a:\n",
    "        print(a, 'SKIP')\n",
    "        continue\n",
    "    # Handles 2 naming conventions that were used at different times\n",
    "    try:\n",
    "        dt = pd.to_datetime(a[:10].replace('_','-'))\n",
    "        multi = True\n",
    "    except:\n",
    "        try:\n",
    "            dt = pd.to_datetime(a[-6:])\n",
    "            multi = False\n",
    "        except:\n",
    "            print(a, 'FAIL')\n",
    "            continue\n",
    "    # if str(dt) > \"2022-08-01\":\n",
    "    #     continue\n",
    "    print(a, dt.date())\n",
    "    book = pd.ExcelFile(src, engine='openpyxl')\n",
    "    # Again, handles the 2 different versions with different sheet names\n",
    "    if multi:\n",
    "        sheets = {sheet:sheet for sheet in book.sheet_names if sheet.isnumeric() and int(sheet) % 100 in [1,6,8]}\n",
    "    else:\n",
    "        sheets = {a[:6]: book.sheet_names[0]}\n",
    "    for term_code, sheet in sheets.items():\n",
    "        trg = target / f'{term_code}/flg_{term_code}_{dt.date()}.parquet'  # target parquet file\n",
    "        if not trg.exists():\n",
    "            print(trg)\n",
    "            trg.parent.mkdir(parents=True, exist_ok=True)\n",
    "            df = (\n",
    "                spriden\n",
    "                .assign(current_date=dt)\n",
    "                .merge(book.parse(sheet).prep(), on='id', how='right')\n",
    "                .drop(columns=['id','last_name','first_name','mi','pref_fname','street1','street2','primary_phone','call_em_all','email'], errors='ignore')\n",
    "            )\n",
    "            df.to_parquet(trg)\n",
    "            mask = df['pidm'].isnull()\n",
    "            if mask.any():\n",
    "                df[mask].disp()\n",
    "    # assert 1==2\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "flags",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
